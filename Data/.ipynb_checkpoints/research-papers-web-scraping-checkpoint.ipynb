{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNF5bFOegMoD"
   },
   "source": [
    "# **Aerial Image Analysis Research Papers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfC9_jIv16sN"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://imgur.com/f5L9s74.jpg\" width=\"800\" height=\"400\" >\n",
    "</center>\n",
    "\n",
    "Every researcher needs an excellent platform where he can freely access the literature of various areas. Hence Google scholar is one of the best freely accessible search engines, which provides a wide variety of published literature in the form of articles, research papers, etc.\n",
    "\n",
    "But sometimes, over choice leads to confusion. So **Web Scraping** is a method that provides a way to collect information from the website in a meaningful manner based on our interests.\n",
    "\n",
    "In this project, we collect information about the research papers related to aerial image analysis. The implementation of this project will use the python library and Beautiful soup. \n",
    "\n",
    "We will collect the information in the form of :\n",
    "1. Title of the paper\n",
    "2. Number of citation\n",
    "3. Author of the paper\n",
    "4. Year of Publication\n",
    "5. Place of Publication\n",
    "\n",
    "We will store this information in the dictionary. And this dataset will be save as in a tabular database, in CSV format, and can be helpful for the literature survey in this area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3407,
     "status": "ok",
     "timestamp": 1626593416580,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "ozQoNWPMq2Lp"
   },
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX2Sk4XTq2Lo"
   },
   "source": [
    "# Libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1626593430003,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "osu4mDm8q2Lp"
   },
   "outputs": [],
   "source": [
    "#import the liberary\n",
    "import requests\n",
    "from time import sleep \n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbc8CwrRXz-w"
   },
   "source": [
    "# Define Header \n",
    "\n",
    "Here we define the header which will help to scrape those webpage which required login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1626593435380,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "Xzpv20vWrUJR"
   },
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Linux; Android 5.1.1; SM-G928X Build/LMY47X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.83 Mobile Safari/537.36'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsmxJtFzMNhp"
   },
   "source": [
    "# Define Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1626593438962,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "1Bli1FmCrgK_"
   },
   "outputs": [],
   "source": [
    "def get_paperinfo(paper_url):\n",
    "    response=requests.get(url,headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print('Status code:', response.status_code)\n",
    "        raise Exception('Failed to fetch web page ')\n",
    "\n",
    "    paper_doc = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "    return paper_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1626593443599,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "wKZN6yG2Mo2o"
   },
   "outputs": [],
   "source": [
    "def get_tags(doc):\n",
    "    paper_tag = doc.select('[data-lid]')\n",
    "    cite_tag = doc.select('[title=Cite] + a')\n",
    "    link_tag = doc.find_all('h3',{\"class\" : \"gs_rt\"})\n",
    "    author_tag = doc.find_all(\"div\", {\"class\": \"gs_a\"})\n",
    "    \n",
    "    return paper_tag,cite_tag,link_tag,author_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1626593445550,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "W29JBUEEM1Qa"
   },
   "outputs": [],
   "source": [
    "def get_papertitle(paper_tag):\n",
    "    paper_names = []\n",
    "  \n",
    "    for tag in paper_tag:\n",
    "    paper_names.append(tag.select('h3')[0].get_text())\n",
    "\n",
    "  return paper_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1626593447165,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "puthH2aCJpF-"
   },
   "outputs": [],
   "source": [
    "# it will return the number of citation of the paper\n",
    "def get_citecount(cite_tag):\n",
    "  cite_count = []\n",
    "  for i in cite_tag:\n",
    "    cite = i.text\n",
    "    if i is None or cite is None:  # if paper has no citatation then consider 0\n",
    "      cite_count.append(0)\n",
    "    else:\n",
    "      tmp = re.search(r'\\d+', cite) # its handle the None type object error and re use to remove the string \" cited by \" and return only integer value\n",
    "      if tmp is None :\n",
    "        cite_count.append(0)\n",
    "      else :\n",
    "        cite_count.append(int(tmp.group()))\n",
    "\n",
    "  return cite_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1626593449626,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "k47snBetKcxk"
   },
   "outputs": [],
   "source": [
    "# function for the getting link information\n",
    "def get_link(link_tag):\n",
    "\n",
    "  links = []\n",
    "\n",
    "  for i in range(len(link_tag)) :\n",
    "    links.append(link_tag[i].a['href']) \n",
    "\n",
    "  return links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1626593452053,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "S98Dy-d4LiJp"
   },
   "outputs": [],
   "source": [
    "# function for the getting autho , year and publication information\n",
    "def get_author_year_publi_info(authors_tag):\n",
    "  years = []\n",
    "  publication = []\n",
    "  authors = []\n",
    "  for i in range(len(authors_tag)):\n",
    "      authortag_text = (authors_tag[i].text).split()\n",
    "      year = int(re.search(r'\\d+', authors_tag[i].text).group())\n",
    "      years.append(year)\n",
    "      publication.append(authortag_text[-1])\n",
    "      author = authortag_text[0] + ' ' + re.sub(',','', authortag_text[1])\n",
    "      authors.append(author)\n",
    "  \n",
    "  return years , publication, authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH7mQOZaYKW9"
   },
   "source": [
    "# Store the information in dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1626593455487,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "s_WJAWHbQJy0"
   },
   "outputs": [],
   "source": [
    "# creating final repository\n",
    "paper_repos_dict = {\n",
    "                    'Paper Title' : [],\n",
    "                    'Year' : [],\n",
    "                    'Author' : [],\n",
    "                    'Citation' : [],\n",
    "                    'Publication' : [],\n",
    "                    'Url of paper' : [] }\n",
    "\n",
    "# adding information in repository\n",
    "def add_in_paper_repo(papername,year,author,cite,publi,link):\n",
    "  paper_repos_dict['Paper Title'].extend(papername)\n",
    "  paper_repos_dict['Year'].extend(year)\n",
    "  paper_repos_dict['Author'].extend(author)\n",
    "  paper_repos_dict['Citation'].extend(cite)\n",
    "  paper_repos_dict['Publication'].extend(publi)\n",
    "  paper_repos_dict['Url of paper'].extend(link)\n",
    "\n",
    "  return pd.DataFrame(paper_repos_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGqG2EP9Q8In"
   },
   "source": [
    "# Iterating over the each page of **Google Scholar** \n",
    "\n",
    "Here we are scraping the total 10 pages of data. We can scrape more .For this we need to change the number in the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 334744,
     "status": "ok",
     "timestamp": 1626593811496,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "hMVQEyDRQ50K"
   },
   "outputs": [],
   "source": [
    "for i in range (0,110,10):\n",
    "\n",
    "  # get url for the each page\n",
    "  url = \"https://scholar.google.com/scholar?start={}&q=object+detection+in+aerial+image+&hl=en&as_sdt=0,5\".format(i)\n",
    "\n",
    "  # function for the get content of each page\n",
    "  doc = get_paperinfo(url)\n",
    "\n",
    "  # function for the collecting tags\n",
    "  paper_tag,cite_tag,link_tag,author_tag = get_tags(doc)\n",
    "  \n",
    "  # paper title from each page\n",
    "  papername = get_papertitle(paper_tag)\n",
    "\n",
    "  # year , author , publication of the paper\n",
    "  year , publication , author = get_author_year_publi_info(author_tag)\n",
    "\n",
    "  # cite count of the paper \n",
    "  cite = get_citecount(cite_tag)\n",
    "\n",
    "  # url of the paper\n",
    "  link = get_link(link_tag)\n",
    "\n",
    "  # add in paper repo dict\n",
    "  final = add_in_paper_repo(papername,year,author,cite,publication,link)\n",
    "  \n",
    "  # use sleep to avoid status code 429\n",
    "  sleep(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96UB_qhBYyXT"
   },
   "source": [
    "# Display of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1626593840640,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "3FwYrkdAjEDC",
    "outputId": "3f40e9e5-4595-4128-d4c4-35fa21300822"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1626593846265,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "F0aKyalSRP3d",
    "outputId": "1366fdc3-b508-439d-96d1-f26e8255c32d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Citation</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Url of paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOTA: A large-scale dataset for object detecti...</td>\n",
       "      <td>2018</td>\n",
       "      <td>GS Xia</td>\n",
       "      <td>624</td>\n",
       "      <td>openaccess.thecvf.com</td>\n",
       "      <td>http://openaccess.thecvf.com/content_cvpr_2018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Convolutional neural network based automatic o...</td>\n",
       "      <td>2016</td>\n",
       "      <td>I Ševo</td>\n",
       "      <td>143</td>\n",
       "      <td>ieeexplore.ieee.org</td>\n",
       "      <td>https://ieeexplore.ieee.org/abstract/document/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Orientation robust object detection in aerial ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>H Zhu</td>\n",
       "      <td>141</td>\n",
       "      <td>ieeexplore.ieee.org</td>\n",
       "      <td>https://ieeexplore.ieee.org/abstract/document/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clustered object detection in aerial images</td>\n",
       "      <td>2019</td>\n",
       "      <td>F Yang</td>\n",
       "      <td>54</td>\n",
       "      <td>openaccess.thecvf.com</td>\n",
       "      <td>http://openaccess.thecvf.com/content_ICCV_2019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patch-level augmentation for object detection ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>S Hong</td>\n",
       "      <td>11</td>\n",
       "      <td>openaccess.thecvf.com</td>\n",
       "      <td>http://openaccess.thecvf.com/content_ICCVW_201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Axis learning for orientated objects detection...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Z Xiao</td>\n",
       "      <td>16</td>\n",
       "      <td>mdpi.com</td>\n",
       "      <td>https://www.mdpi.com/663030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Feature extraction by rotation-invariant matri...</td>\n",
       "      <td>2017</td>\n",
       "      <td>G Wang</td>\n",
       "      <td>39</td>\n",
       "      <td>ieeexplore.ieee.org</td>\n",
       "      <td>https://ieeexplore.ieee.org/abstract/document/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Density map guided object detection in aerial ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>C Li</td>\n",
       "      <td>11</td>\n",
       "      <td>openaccess.thecvf.com</td>\n",
       "      <td>http://openaccess.thecvf.com/content_CVPRW_202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adaptive anchor for fast object detection in a...</td>\n",
       "      <td>2019</td>\n",
       "      <td>R Jin</td>\n",
       "      <td>6</td>\n",
       "      <td>ieeexplore.ieee.org</td>\n",
       "      <td>https://ieeexplore.ieee.org/abstract/document/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Learning roi transformer for oriented object d...</td>\n",
       "      <td>2019</td>\n",
       "      <td>J Ding</td>\n",
       "      <td>129</td>\n",
       "      <td>openaccess.thecvf.com</td>\n",
       "      <td>http://openaccess.thecvf.com/content_CVPR_2019...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Paper Title  ...                                       Url of paper\n",
       "0  DOTA: A large-scale dataset for object detecti...  ...  http://openaccess.thecvf.com/content_cvpr_2018...\n",
       "1  Convolutional neural network based automatic o...  ...  https://ieeexplore.ieee.org/abstract/document/...\n",
       "2  Orientation robust object detection in aerial ...  ...  https://ieeexplore.ieee.org/abstract/document/...\n",
       "3        Clustered object detection in aerial images  ...  http://openaccess.thecvf.com/content_ICCV_2019...\n",
       "4  Patch-level augmentation for object detection ...  ...  http://openaccess.thecvf.com/content_ICCVW_201...\n",
       "5  Axis learning for orientated objects detection...  ...                        https://www.mdpi.com/663030\n",
       "6  Feature extraction by rotation-invariant matri...  ...  https://ieeexplore.ieee.org/abstract/document/...\n",
       "7  Density map guided object detection in aerial ...  ...  http://openaccess.thecvf.com/content_CVPRW_202...\n",
       "8  Adaptive anchor for fast object detection in a...  ...  https://ieeexplore.ieee.org/abstract/document/...\n",
       "9  Learning roi transformer for oriented object d...  ...  http://openaccess.thecvf.com/content_CVPR_2019...\n",
       "\n",
       "[10 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8CfiuluR36F"
   },
   "source": [
    "# Storing in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1626593904758,
     "user": {
      "displayName": "Nandini Saini (MP19AI003)",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlhy2s3AWzNCl3CRDSpIDvMLZF0vUfsv7e2t-=s64",
      "userId": "16954306187614037648"
     },
     "user_tz": -330
    },
    "id": "TUbho4VdVkpz"
   },
   "outputs": [],
   "source": [
    "final.to_csv('aerial_image_reserachpapers.csv', sep=',', index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLVnqVl6ZXbw"
   },
   "source": [
    "# Summary\n",
    "\n",
    "In this project, we accumulated information about research papers in the area of aerial images from the website (https://scholar.google.com/).\n",
    "\n",
    "![](https://imgur.com/KYojxqI.jpg)\n",
    "\n",
    "The metadata gathered about the various published research papers title, in which year and which journal/conference these published, who are the authors, and link of the papers. \n",
    "\n",
    "\n",
    "To scrape these pieces of information, we have taken the followings steps :\n",
    "1. Scraped the web page content using the Beautiful Soup library.\n",
    "2. Define the function for the these things :\n",
    "    - Extracting tags for relevant parts\n",
    "    - Using tag , extract data for the paper title name , authors , year , number of citations etc. \n",
    "3. Iterate above steps for the each web page and collect data from 10 pages.\n",
    "4. Store this dataset in the format of csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgBAOedId60w"
   },
   "source": [
    "# Future Works\n",
    "\n",
    "The current web-scraping project is collecting all the papers of the area in aerial image analysis. It can be more generalized if we scrape papers for any defined area. From this scraped data, we can visualize the research area that which papers get more citations, how much work is happening in this area, what are the top papers along with top conferences/journals. This data can also help to make a detailed literature survey on the specific area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHCt8oN3eIPH"
   },
   "source": [
    "# Refrences\n",
    "\n",
    "\n",
    "\n",
    "1.  https://jovian.ai/learn/zero-to-data-analyst-bootcamp/lesson/web-scraping-and-rest-apis\n",
    "2.  https://docs.python-requests.org/en/master/\n",
    "3. https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "4. https://www.tutorialspoint.com/requests/requests_web_scraping_using_requests.htm\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5AP8NWtobraf",
    "outputId": "0a7a4489-ef3b-439e-8a47-12883a151d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Detected Colab notebook...\u001b[0m\n",
      "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
      "API KEY: "
     ]
    }
   ],
   "source": [
    "jovian.commit(project=\"dataanalyst-bootcamp-project1-web-scraping\", outputs=['aerial_image_reserachpapers.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxNZMz8-fx69"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "research-papers-web-scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
